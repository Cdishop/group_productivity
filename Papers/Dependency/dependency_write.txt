
The nature of work is changing such that the connections between tasks and actors are increasingly relevant levers for understanding and benefiting from human capital. Five times as many Americans are employed in service jobs compared to those in manufacturing and production [@ford_service-dominant_2008; @parker_future_2001], signaling the shift from a manufacturing economy of additive tasks to a market economy of knowledge and service in which organizational success is driven by the complex interplay between customers, employees, and stakeholders. Changes in information, communication, and transportation technology fueled flatter firm hierarchies, virtual and telework, and teams as the building blocks of modern organizations [@mathieu_review_2014] where employees must manage work flows and coordinate their activities to perform at high levels [@kozlowski_groups_2012]. Organizational scientists now emphasize questions about connections and interdependence among employees who collaborate with and receive feedback from their coworkers [@grant_7_2009] because the interplay of task and social relations among team members is thought to either relate to outcomes such as collective efficacy, cohesion, behavioral processes, and performance [@courtright_structural_2015] or create the context in which team behaviors unfold through time [@marks_temporally_2001; @baard_performance_2014]. Understanding the nature of dependence among actors will enable organizations to better design, train, develop, and motivate personnel for effective teamwork, whereas endeavors that fail to consider interdependence have "little relevance to building knowledge in the work groups and team literatures" [kozlowski2003work, p. 363].

Interdependence or dependency (defined later) has received increasing attention among organizational researchers, and most tie their work in some way to the notions of Thompson's (1967) task workflows, Mohr's (1971) writing on the extent to which individuals perceive that they have "one person" jobs, or Penning's (1975) bases of interconnectedness. Bell and Kozlowski [-@bell_typology_2002] present a typology of virtual teams where interdependency is one of the main features distinguishing different team types; @morgeson2012work and @grant_7_2009 review the work design literature and present task interdependence as a key feature for understanding organizational behavior; @kiggundu_task_1981 presents a theory of how interdependence relates to feelings of responsibility to one's work; @lenox_interdependency_2007 use interdependence in their theory on why firms rise and fall within an industry over time; and @puranam_organization_2012 predict relationships between organization design, information processing, and interdependence. Empirical studies on interdependence, both as a predictor and outcome, slowed after initial reports by @ven_determinants_1976 and @cheng_interdependence_1983 but have recently reemerged in the literature [e.g., @de_dreu_cooperative_2007; @grant_significance_2008; @hertel_managing_2004; @lee_shin_ki_2018].  

Although these reviews, theories, meta analyses, and empirical studies have increased our understanding of interdependence in organizations and teams, its measurement and operationalization have yet to be unified or organized. Items sometimes measure interdependence without attending to (and perhaps confounding) its various directions, such as initiated and received (kugg) or reciprocal (cite). There are different domains that it can apply to, such as role, task, or outcome dependence (cite), different levels of abstraction, such as whether the measure applies to the individual, dyad, group, or firm (cite), and it has been proposed as a way to create typologies both for teams and tasks (hollenbeck). Many of these issues have been refined conceptually, especially within a recent meta analysis by Courtright et al. (2015), but the literature contains little guidance on where the field stands with respect to interdependence measurement. Moreover, there are theoretical indices, observational measures, self reports, discrete task counts, workflow images used in supervisor interviews, formal equations for agent-based models, network indices, and algorithms for computing dependence based on resource exchanges all as methods of indicating the level of interdependence in a given setting. The purpose of this paper is to organize this material, provide a taxonomy of interdependence measures, and link measures to specific purposes so that future research can appropriately align measurement with theory. 

The contributions of this paper are as follows. First, we provide a resource for identifying various interdependence measures and their purpose. Gathering the array of measures into a single location allows us to better understand what they capture and how they can be used, notice inconsistencies and areas for improvement, and provides directions for future research. Each of these components will be discussed in this paper. By organizing and reflecting, we are also able to place attention on old indices that are useful but have been underappreciated. Interdependence measurement today is dominated by self reports, but there were a number of relevant theoretical indices proposed in the 60's, 70's, and 80's that we hope to re-highlight. Second, we draw attention to aggregation and the multi level nature of interdependence. As discussed later, there is a growing emphasis on initiated, received, and reciprocal interdependence as various arrangements at play in a task environment. Although researchers acknowledge that these constructs are related, their measurement occurs without discussion about the appropriate way to aggregate or compile one construct to another. We recast this discussion in terms of Chan's (1998) composition framework and multi level theory to better appreciate the various levels that interdependence can subsume. Third, any clarity that comes from interependence measurement should advance theory in this area. By reflecting on how interdependence is operationalized and measured, new ideas emerge that we hope ignites better theory. Seeing all of the measures at once also helps identify confounds that merit theoretical scrutiny in future work, we discuss those later. Finally, our paper is a launching point for research, argument, and hopefully eventual consensus on the merits of various interdependence indices. Our literature has witnessed heated debates about agreement indices, structural equations modeling fit statistics, difference scores, diversity indices, and how to appropriately represent person-environment fit. All of these areas worked out best methods, practices, and interpretations of various indices. Our paper is a signal that interdependence deserves something similar. 

We begin by discussing interdependence and its various dimensions. Next, we present our taxonomy and way of organizing the interdependence measures and indices. After unpacking and reviewing the material, we discuss challenges, provide recommendations, and point to next steps for research. 

# Structural Interdependence

Interdependence has been discussed across many reviews in fields ranging from organizational psychology to political science, strategy, and management (cites). Theoretical clarity on its different forms was provided in a meta analysis by Courtright et al. (2015); we follow their organization to introduce this material. Structural interdependence refers to features of the team -- such as resources and workflows as well as goal and reward systems that can be deliberately manipulated by team leaders and members -- that define the interconnectedness of team members (Wageman, 1999). Courtright et al. (2015) note that,

>> team members and leaders choose low [structural] interdependence when they structure tasks on an individual basis with a pooled product, when they form the team with resources redundant across team members, or when they establish goal and reward systems that primarily emphasize individual contributions over collective outputs. In contrast, they choose high [structural] interdependence when members simultaneously work on all aspects of the task, when they intentionally form groups with members processing varied access to resources, or when they establish goal and reward systems that primarily emphasize collective outputs. (p. 3). 

Structural interdependence is distinct from teamwork behaviors such as planning, monitoring progress, confidence building, and backup behaviors (marks matheiu), which are referred to collectively as behavioral processes in the teams literature (DeChurch & Mesmer-Magnus, 2010). Shea and Guzzo (1987) and Wageman (1999) referred to actual team behaviors and interactions as an alternative form of interdependence, called behavioral interdependence, meaning, for example, if workers on assembly line "A" interact more than workers on assembly line "B" then those in "A" have greater behavioral interdependence. But Courtright et al. (2015) note that this idea is largely captured within the behavioral processes outlined in the groups and teams literature. Our paper focuses on measures and theoretical indices for structural interdependence. 

# Forms of Structural Interdependence - Task and Outcome

Different labels exist for the various dimensions of structural interdependence, but they can largely be classified within two areas: task and outcome interdependence. Task interdependence refers to "the degree to which taskwork is designed so that members depend upon one another for access to resources and create workflows that require coordinated action" (Courtright et al., 2015, p. 4). It captures what Mathieu, Maynard, Rapp, and Gilson (2008) called means interdependence, what Van de Ven and Ferry (1980) and Thompson (1967) called task interdependence or the notion of workflow patterns, what Aurther Jr. et al. (2012) called team relatedness and workflow, O'Brien's (1968) notions of collaboration and coordination, and the dimensions of role theory outlined by Oeser and Harary (1962). Research in this area focuses on how tasks are divided among the group, the precedence relationships among tasks and roles, the extent to which members depend on one another for skills, data, materials, information, and other resources, the combination of task accomplishments into a final product, the exent to which members work individually versus in a group, and the flow of materials across members. 

Outcome interdependence refers to "the degree to which the outcomes of taskwork are measured, rewarded, and communicated at the group level so as to emphasize collective outputs rather than individual contributions" (Courtright et al., 2015, p. 4). It captures what Puranam, Reveendran, and Knudsen (2012) called agent interdependence, what Barrick et al. (2007) called psychological interdependence, what Pennings (1974) called social interconnectedness, what Tosvold (1986) called goal interdependence, and the notions of payoff differences with respect to what Victor and Blackburn (1987) called reflexive, fate, and behavioral control. Research in this area focuses on whether goals and feedback are provided at the individual versus team level, the nature of feedback and rewards and whether they are contingent on individual or group contributions, and how performance is aggregated and communicated. 

# Taxonomy and Classification

Although researchers operationalize interdependence in a variety of ways, they can largely be partitioned into two domains: self reports and theoretical indices. Self reports are administred to team members, leaders, or supervisors and the individuals are then asked to indicate their perceived interdependence, whereas theoretical indices are formulas or methods for researchers to compute values of interdependence based on theorized or observed workflow patterns, goal structures, or task interactions. Within each of these broad discussion areas (i.e., self reports and theoretical indices) we discuss task and outcome interdependence and also futher distinctions such as initiated and received (defined below) interdependence, whether the measure is used at the individual or team level, example items and uses, and provide recommendations, critiques, and research agendas for future work. 

## Self Reports

Table 1 presents self-report measures of task interdependence. Items in this space assess perceptions about workflow patterns and the extent to which one or more tasks must be completed before others are initiated. Sample items include, "One task needs to be performed before the other task" (Wong & Campion, 1991), and "Unless my job gets done, other jobs cannot be completed" (Morgeson & Humphrey, 2006). A handful of both individul and team level measures exist. Items at the individual level assess how one individual perceives his or her task in relation to others, e.g. "The way I perform my job has significant impact on others" (Pearce & Gregersen, 1991), whereas team level measures emphasize dependence without reference to any single individual, "Within my team, jobs performed by team members are related to one another" (Lee, Shin, & Ki, 2018). As shown, most scales emphasize the individual level; a few contain both individual and team-referent items. 

Researchers using self reports have also distinguished between initiated, received (Kiggundu, 1981), and later reciprocal interdependence (Pearce & Gregersen, 1991). All are forms of task interdependence, but initiated occurs when "work flows from the focal employee to others" (Grant & Parker, 2009), whereas received interdependence emphasizes how the focal employee is affected by work from others (Kiggundu, 1981). When both occur, the focal node is said to be under reciprocal interdependence. Moregeson and Humphrey (2006) provide a scale for both initiated and received interdependence, whereas Pearce and Gregersen (1991) provide items that measure reciprocal interdependence and *independence*. Other existing measures tend to emphasize reciprocal (e.g., Campion, Medsker, & Higgs, 1993; Wong & Campion, 1991) or mix items that reflect initiated, received, and reciprocal interdependence (e.g., Lee, Shin, & Ki, 2018; Pennings, 1975). 

Individuals typically respond to task interdependence items with respect to all of their tasks, meaning that a focal individual is asked not about a defined activity such as giving a presentation but, instead, about her perceived interdependence in general. The exception is a study and measure provided by Arthur et al. (2012). These researchers created a list of tasks that F-16 pilots completed during their training, gathered subject-matter-expert ratings of the interdependence among those tasks that could be used as an "objective" standard, and then created measures that were completed by individual pilots concerning their perceptions of interdependence *for each individual task*. The perceptions that emerged from the self reports then matched the SME-classified high, medium, and low task interdependent activities. The questionnaire provided by the authors is reprinted in Figure 1. For each task, individuals were asked to rate the extent to which they were required to work with other team members and then mark the pattern of workflow, such as pooled, sequential, or reciprocal. These authors also uniquely differentiate between team-relatedness, or the extent to which successful performance requires task interdependence, and team workflow, or the type of task interdependence as defined by Thompson 1967. The images of task relationships shown in their "team workflow" box are the same as those in Van de Ven, Delbecq, and Koenig (1976) and Thompson (1967): the questionnaire used by Van de Ven et al. (1976) is shown in Figure 2. As shown, the images represent increasingly task interdependent work arrangements, moving from independent to sequential, reciprocal, and then team. Note that Bell and Kozlowski (2002) called the last task interdependence type "intensive" rather than "team." In Arthur et al. (2012), members are asked to rate each task with respect to the task interdependence work flow type, whereas in Thompson (1967) and Van de Ven et al. (1976) individuals are asked to used the images to describe the nature of their work as a whole. 

Moving to outcome interdependence, Table 2 shows self reports currently in the literature. Items in this space assess perceptions about shared goals, e.g., "My work goals come directly from the goals of my team" (Campion et al., 1991) or benefits contingent on group rather than individual contributions, e.g., "Many rewards from my job are determined in large part by my contributions as a team member" (Campion et al., 1991). There are a number of both individual (De Dreu 2001; Campion et al., 1993) and team-referent (Janssen; zhang) measures. Campion et al. provide two separate scales, one for goal and the other for reward interdependence, whereas other researchers assess only goal interdependence (Zhang), reward interependence (de dreu), or use items that tap both domains (janseen). 

### Challenges, Recommendations, and Next Steps

#### 1 Multi Level Composition and Compilation

Our tables reflect whether items assess individual or team perceptions of task/outcome interdependence, and readers will probably consider that notion with a section title labeled "multi level," but the levels issue we draw attention to, instead, is among initiated, received, and reciprocal self reports. Many other discussions about appropriately moving from individual to team-reference measures exist (cites), but the idea that reciprocal is on a different level than initiated or received has gone unnoticed. In our view, initiated and received task interdependence are two constructs that concern the perceptions of a single node. Reciprocal interdependence, though, requires multiple (at least two) nodes with shared perceptions about interdependence. 

To appreciate this idea fully, work up from an understanding of initiated and received at the individual level. Initiated has to do with work flowing out of a given node, and is assessed with items such as, "Unless my job gets done, other jobs cannot be completed." Received also concerns a single node, but it concerns work flowing into a given node, "My job cannot be done unless others do their work." These are perceptions at the individual level regarding a given task or job. When both are at play, researchers label the measure as reciprocal and use items such as, "The way I perform my job has a significant impact on others" and "My own performance is dependent on receiving accurate information from others." Our concern is not with the items or assessed construct, but with its label. To say that something is reciprocal is to imply words such as mutual, common, joint, corresponding, and complementary, meaning that more than one node has to agree with the pattern of in and out flows. There is an additional, untapped area for researchers to assess, which is the extent to which the perceptions of task outflows from one individual are shared by task inflow perceptions from another. If Jacob perceives outflow from his task in the direction of Roxanne, does Roxanne share that perception in the form of receiving inputs from Jacob? In our view, that is what reciprocal means (and it is consistent with Thompson's original 1967 writing and Van de Ven et al.'s 1976 instrument). 

What we are arguing for as next steps, then, is one of two directions. Either the current label given to reciprocal items such as those in Table 1 is replaced by a new term, such as "both," "full-flow," or "IR interdependence" and reciprocal is reframed to mean what we described above, or -- and probably the more reasonable approach given that reciprocal measures already exist -- future research considers how to extend reciprocal and perhaps introduce a new term that captures agreement between task in and out-flows as originally implied by Van de Ven et al. (1976). Again, given that reciprocal already exists in the literature and a number of measures are at play, it makes sense to leave the label as is and adopt the second approach in future work. 

Irrespective of the route, future work can leverage existing discussions in Chan (1998) and Kozlowski and Klein (2000) for how to proceed. An additive approach would simply sum or average the scores from two nodes regarding their task interdependence, whereas a direct consensus approach would entail an additional agreement score to justify aggregation. The more rigorous approach would be to provide both "I" and "We"-referent questions to both nodes, use an agreement index on the "I" scales to justify aggregation, and treat the "We"-phrased measure as the higher level construct. Essentially, we are recasting the idea of intiated/received versus reciprocal into a levels idea from individual to dyadic.

#### 2 Task, Job, Person

The second tension is whether the focal node is a task, job, or person. Descriptions differ across reviews and theories. For instance, Kiggundu (1981) describes initiated interdependence as the degree to which work flows from a particular *job* to one or more other jobs, whereas Grant and Parker (2009) state that it occurs when work flows from a particular *employee* to others. These differences carry over into measurement items, which sometimes refer to tasks, e.g., "How well one task is performed has a great effect on how well the other task can be performed" (Wong & Campion, 1991) and at other times reflect the person or job, "My job cannot be done unless others do their work" (Morgeson & Humphrey, 2006). 

In our view, there is a greater tension here than simple wording differences. It is a theoretical and empirical question as to whether the mechanisms differ if the focal node of interdependence is a task, job, or person. If they do, it remains to be seen how much of an effect that has across the various measures. But the notion we want to point out is that measures should align with theory. If the theory and arguments being tested concern tasks, it may not be appropriate to use items that refer to jobs. Wong and Campion (1991) have argued that jobs are aggregations of tasks, which means that theorizing about one but measuring the other without justifying the translation in either direction would be untenable in the same sense as theorizing about individuals but measuring only team-level variables (some kozlowski cite). 

#### 3 Purpose and Inference

Much like the application of a statistical model to data, we recommend that researchers think hard about the inference they wish to make and use that reasoning as a basis for which measure to choose. Our tables provide references and can be used as a guide for where to turn given a researcher's particular interest. Poor preparation or justification can lead to an accumulation of innapropriate items, construct redundancy, or contamination, especially in the organizational structure space where there are a vast number of related ideas with potentially overlapping items: coordination, cooperation, conflict, formalization, specialization, roles, tasks, jobs, etc.

## Theoretical Indices

Researchers have also operationalized interdependence by presenting a number of formalas or methods for calculating an interdependence value outside of any perception by an individual emeshed within the task network. An index of task interdependence, for example, could come from a count of the number of task precedence relationships that exist in a unit, or, in other words, the number of tasks that require other tasks to be completed before they themselves can occur. The value of interdependence in these measures, therefore, comes from the researcher either presuming task relationships and structure in a theory or observing it in the field, although the latter is far less common.

Table 3 depicts interdependence indices. The first five come from the organizational science literature, whereas the last three are pulled from the computer science and software engineering literatures. Indices provided by O'Brien (1968) and others cohere most directly with the notion of task interdependence represented in self reports, so we begin there. First, consider task precedence indices provided by O'Brien (1968), Wood (1986), and Oeser and O'Brien (1967) -- row one of Table 3. These indices quantify the amount of precedence relationships in a task network. As shown in the images, when task one must be completed before task two, which must be completed before task three, which must be completed before task four, the index is greater than when tasks one, two, and three feed into task four but none of the first three tasks require precedent completions. In other words, a low value of the index means that tasks can be completed irrespective of the status of other tasks, performance on one does not depend on the performance or completion of another. Oeser and O'Brien (1967) originally introduced this index simply as the "task by task" matrix in their structural role theory, which was adopted and transformed slightly by O'Brien (1968) and called the inter-task coordination index, and later used as part of a task complexity taxonomy by Wood (1986) and labeled coordinative complexity. The index associated with Oeser and O'Brien's (1967) task by task matrix can take on any positive, real value (zero included), whereas the inter-task coordination index provided by O'Brien (1968) is bounded by 0 and 1. Wood's (1986) coordinative complexity index is identical to O'Brien's (1968) inter-task coordination index. Note that the values we use in the example image include 10 and 3, so they come from Oeser and O'Brien's (1967) task by task matrix, but the other index would also classify the first task structure as more interdependent given the greater number of precedence relationships. 

Row two of Table 3 presents another common theoretical task interdependence index that is often ignored or confounded in self report ratings: the extent to which individuals work jointly on tasks. Now, the emphasis is not on precedence relationships or the extent to which tasks must be completed before others, but on the allocation of people to tasks and the extent to which people overlap in those assignments. To what extent is a given task completed by a single or multiple individuals? Oeser and Frank (1962, 1964) originally introduced this index in their person by task matrix within structural role theory, and, as with the other index, O'Brien (1968) later adopted it and provided a scaling between 0 and 1 that he called inter-position collaboration. The images show two possible ways to assign two individuals to two tasks. In the first, each task is completed by a single individual so the index takes on a low value, whereas the index increases for the second arrangement where task one undergoes joint performance by both individuals. 

The next row of Table 3 describes the NK model of interdependence presented in the strategy literature by @lenox_2007. This index captures the complexity of task or activity configurations within a unit. Imagine a unit or team with four tasks, A, B, C, and D, and assume that A depends on B and there are no other task dependencies. Take task A to be "training" and task B to be "find a manager to train the unit," where each can take on a binary value, 0 or 1, in which the options for A include error management or active learning whereas those for B include two different managers, Joe and Kelly. We can represent an arrangement in a task vector, such as [0, 1], which, in this case, means that the unit received error management training by Kelly, whereas the vector [1, 1] would mean that the unit received active learning training by Kelly. Given that A depends on B in this example, there are four task vectors that may produce unique values of performance for the unit: [0, 0], [0, 1], [1, 0], and [1, 1]. Said differently, the results of tasks A and B with respect to unit performance (or any other relevant outcome) could potentially differ in four ways due to the task arrangements that stem from interdependence. When task A depends not only on B but also on C, there are eight unique (binary) configurations, and when A then also depends on D there are 16 unique (binary) configurations. This index, therefore, represents the increasing number of potential results as tasks begin to depend on one another. 

The next three task interdependence indices in Table 3 come from software engineering and computer science: syntactic, workflow, and logical dependency. Before discussing them, it helps to briefly unpack common work activities for programmers. Imagine an individual who writes a script that will eventually become a website for a blog about cooking, music, and current events. The blog contains posts about the various topics, images displayed on each page, an interesting design in the background, links to similar material on other sites, and compiled reports on US trends garnered from scraping data from other places on the web. Often, code for different tasks will be stored within different scripts. One script may scrape and clean data from the web while another searches for and prepares links to other relevant material. A third script contains the text for each post, a fourth prepares images and charts. A master script then references each of these individual scripts and ultimately compiles the website, and, back down a level of abstraction, each individual script may reference yet other scripts that initiate basic functions and objects. All of the ways in which these various scripts "reference" one another, or pull code from different sources, creates dependence in a similar way that tasks more familiar to organizational psychologists do. The other aspect that merits attention before discussing dependence is commits. After writing code for one or several files, a programmer then commits her changes either to be checked by others or maintained indefinitely by the website. With these basic notions in mind, syntactic, workflow, and logical become easier to understand.

Syntactic dependency refers to the number of code references either across all scripts or within a single file. When Justin's code references two other files, A and B, his script is said to have less syntactic dependency than Rachel's code that references six other files. It can also be applied to the entire workflow of the unit to be compared with another. Think back to the cooking, music, and current events blog mentioned above, perhaps its code, as an entire unit, contains greater syntactic dependency than the files, as a unit, from another site on sports commentators within the US. Whenever a script or set of scripts reaches elsewhere for additional code, syntactic dependency increases. 

Logical dependency is similar, but it incorporates commits. Essentially, this index captures the extent to which files, when worked on, require other scripts to be updated as well within the same commit. [More here after working out note within table]. 

Workflow dependency, finally, is the degree centrality of the person with the greatest degree centrality out of all of the people working on a script. Imagine two different scripts, A and B, each with an assortment of different people writing their code. Susie, Sarah, Savannah, Sam, and Sheryl write code within script A, whereas Robert, Rachel, Rome, Rupert, and Robin write code within script B. Out of all the people working on script B, Rome has the greatest degree centrality (4). Sarah, on the other hand, has the greatest degree centrality out of all of the people working on script A (10). Script A, then, is said to have greater workflow dependency than script B. 

Indices of outcome, rather than task, interdependence were presented in Victor and Blackburn's (1987) writing on interdependence theory. They unpacked what is essentially a game theory framework for describing and quantifying actions and outcomes for two or more individuals. The matrix representation used in their paper is identical to normal form games in economics where players are situated either on the row or the column, along with their possible actions, and the values in the matrix represent the rewards, outcomes, or utilities for the row/column player. The example reprinted in Table 3, for instance, shows that the sales manager receives an outcome of 5 when she conducts action A2 while the credit manager conducts action B1. All of the examples described in their theory use actions and activities, but the ideas generalize to tasks as well. The index that we draw attention to is a number that Victor and Blackburn (1987) call the index of dependence that captures the extent to which the rewards/outcomes for one player are determined by the other player's tasks or actions (this number is not the specific value within an outcome matrix, such as 5 or -4 in the top right cell). For example, for a given move by the credit manager, the sales manager does not change her outcome by switching from action (task) A1 to action (task) A2. In other words, the outcomes associated with the network of tasks or actions is determined by the actions/tasks of the row player but not the column player. In this case, then, the index of dependence for the sales manager is 1, meaning that her outcomes are completely determined by the other player's actions (tasks). 

The index of dependence is computed for every individual in the game so that each person receives his or her own (potentially) unique value, but Victor and Blackburn (1987) also provide a team-level index called the index of correspondence which captures the overlap between rewards governed by an individual's own actions (tasks) and those governed by other's actions (tasks). Imagine a system in which all players have some control over their outcomes given their task choices. Susan, for instance, can choose between writing (task 1) or scheduling meetings (task 2) and those tasks lead to different outcomes such that she has a preference for one over the other. Jackie also has task choices, she can choose to analyze data (task 1) or update the scripts for her shared website with Susan to improve its security (task 2). To the extent that Jackie's task choices influence Susan's outcomes irrespective of whether Susan chooses to write or schedule, Susan's index of dependence will increase -- her outcomes depend not only on her actions or tasks but also on Jackie's. The index of correspondence, conversely, is about the alignment of choices under one's own control with those not under one's own control. To what extent does the unit share preferences for actions, task completions, or task choices? One individual can collect different rewards for making different choices, but rewards are also determined by what the other player's choose. To what extent do those two tensions align?

### Recommendations, Challenges, and Next Steps

#### 1 Index compared to self report

#### 2 Index Dynamics

#### 3 apply to field and see what we have. No data on "non perceived" interdependence

#### 4 Purpose and Inference

# Discussion


